{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5c3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import scipy.stats  # it may be necessary that you install scipy (pip install scipy)\n",
    "import P5_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad45a4",
   "metadata": {},
   "source": [
    "---\n",
    "#### P5: Object classification\n",
    "\n",
    "---\n",
    "<div class=\"alert alert-info\">\n",
    "<p>\n",
    "University of Applied Sciences Munich<br>\n",
    "Dept of Electrical Enineering and Information Technology<br>\n",
    "Institute for Applications of Machine Learning and Intelligent Systems (IAMLIS)<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;(c) Alfred Sch√∂ttl 2023<br>\n",
    "    \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "In this notebook, we will design a simple object classifier which is able to distinguish between gummy bears and pieces of licorice. This notebook relies on helper functions defined in `P5_helpers.py`. Be sure to have this file in the same directory as this file. It is a good idea to go through the file after doing this assignment if you want to know details on how the specific OpenCV functions are called.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe7a3b",
   "metadata": {},
   "source": [
    "### 1. Image acquisition and preprocessing\n",
    "\n",
    "The image acquisition is already prepared for you. We will then preprocess the image by binarizing and cleaning up the segments by some morphological operations. The pipeline is exactly the pipeline we already know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdd2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire(filename):\n",
    "    '''get the grayscale image and the color image of filename'''\n",
    "    orig_img = cv2.imread(os.path.join('imgs', filename))\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    grayscale_img = cv2.cvtColor(orig_img, cv2.COLOR_RGB2GRAY)\n",
    "    return grayscale_img, orig_img\n",
    "\n",
    "def preprocess(img):\n",
    "    '''binarize the image and clean up the segments'''\n",
    "    se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))\n",
    "    img2 = (img < 220).astype(np.uint8)\n",
    "    img2 = cv2.erode(img2, se, iterations=1)\n",
    "    for _ in range(2):\n",
    "        img2 = cv2.dilate(img2, se, iterations=4)\n",
    "        img2 = cv2.erode(img2, se, iterations=4)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c062c",
   "metadata": {},
   "source": [
    "Let's test the acquisition and preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray, img = acquire('gb.jpg')\n",
    "img_preproc = preprocess(img_gray)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,12))\n",
    "P5_helpers.disp_img(axs[0], img)\n",
    "P5_helpers.disp_img(axs[1], img_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3aa4e1",
   "metadata": {},
   "source": [
    "### 2. Segmentation and feature definition\n",
    "\n",
    "We use the function `P5_helpers.compute_contours`, which already implements the contouring algorithm, to find a list of the contours of all segments. _Please complete the function `get_features` to obtain a list of features. There shall be two feature values for each segment._\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a9795",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_features(contours):\n",
    "    available_features = P5_helpers.features(contours)\n",
    "    feats = np.zeros([len(contours), 2])\n",
    "    # loop through all found segments \n",
    "    for k, contour_features in enumerate(available_features):\n",
    "        ### TODO:\n",
    "        # Find two appropriate features. You may derive them from the available features\n",
    "        # 'perimeter', 'area', 'major_axis', 'minor_axis', 'ecc' stored in available_features.\n",
    "        # As an example, 2*available_features['area'] gives you twice the area of the current \n",
    "        # segment. Take care that the derived features are roughly in the range 0..1\n",
    "        feats[k] = ..., ...\n",
    "        ###\n",
    "    return feats\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "contours, contour_img = P5_helpers.compute_contours(img_preproc)\n",
    "P5_helpers.disp_img(ax, contour_img)\n",
    "print(f'Feature values of the {len(contours)} segments:')\n",
    "get_features(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8561cb",
   "metadata": {},
   "source": [
    "### 3. Find the model from the training data\n",
    "\n",
    "We use the images `gb.jpg` containing 5 gummy bears as _**training samples**_ for our model and hope that all other gummy bears look similar. Our model is a normal distribution model. It is therefore sufficient to calculate the mean value and the covariance matrix ot the samples.\n",
    "\n",
    "The function `process` contains the call to our processing steps `acquire`, `preprocess` and `compute_contours` implemented so far. It then calls the function `analyze` which shall return the features `feats`, the mean value `mu` and the covariance matrix `sig` of our data. Complete the function `analyze`.\n",
    "\n",
    "_Hint_: `analyze` may use the numpy functions `np.mean` and `np.cov`. Observe that `np.cov` requires a matrix which contains the samples in _columns_ and the features in _rows_. \n",
    "\n",
    "You should see in the right-hand plot the samples, the mean value and variances of the gummy bears plotted in feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c024eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(filename, class_no):\n",
    "    img_gray, img = acquire(filename)\n",
    "    img_preproc = preprocess(img_gray)\n",
    "    contours, contour_img = P5_helpers.compute_contours(img_preproc)\n",
    "    feats, mu, sig = analyze(contours)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "    P5_helpers.disp_img(axs[0], contour_img)\n",
    "    P5_helpers.plot_feats(axs[1], feats, mu, sig, class_no)\n",
    "    plt.title('Feature space')\n",
    "    return feats, mu, sig\n",
    "\n",
    "def analyze(contours):\n",
    "    ### TODO:\n",
    "    # Assign the variables F, mu, sig the features, the mean value and the empirical covariance matrix.\n",
    "    # - Use the already implemented `get_features` to obtain the features \n",
    "    # - Use `np.mean` to compute the mean value. Make sure that the mean value is a two-dimensional vector!\n",
    "    # - Use `np.cov` to compute the covariance matrix. Make sure that `np.cov` gets a data matrix with the \n",
    "    #   samples in columns and the features in rows.\n",
    "    F   = ...   \n",
    "    mu  = ...\n",
    "    sig = ...\n",
    "    ###\n",
    "    return F, mu, sig\n",
    "\n",
    "feats_gb, mu_gb, sig_gb = process('gb.jpg', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5526d",
   "metadata": {},
   "source": [
    "Repeat the same with class 1 (licorice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7340c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_lic, mu_lic, sig_lic = process('lic.jpg', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59bd0d",
   "metadata": {},
   "source": [
    "Let us plot the features of class 0 (gummy bear, plotted in red) and class 1 (licorice, plotted in green) as well as the pdfs of the normal distribution. We call the adaption of the model to the training data _**learning**_ or _**training**_.\n",
    "\n",
    "_Tip:_ You may not see the features in the plot clearly if they are too close together or out of the range 0..1. Please consider to rescale the chosen features in the function `get_features` in this case. It is also possible to adjust the borders 0 and 1 in the two `np.linspace` commands in the function `P5_helpers.visualize_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P5_helpers.visualize_model(feats_gb, mu_gb, sig_gb, feats_lic, mu_lic, sig_lic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190a5d3",
   "metadata": {},
   "source": [
    "### 4. Bayes classifier\n",
    "\n",
    "Now we are ready to design the Bayes classifier. Let `feats` be the features of an unknown sample. The function `classify_sample` finds the probability densities that this feature vector occurs given that the sample is a gummy bear/piece of licorice. Assume that there are an equal amount of gummy bears and pieces of licorice in the underlying set. The `scipy` function `multivariate_normal(mu, sig).pdf` can be used to compute the pdf of a two-dimensional normal distribution with expectation value mu and covariance matrix sig.\n",
    "\n",
    "Define a rule to decide whether class 0 or class 1 is more likely for the given feature vector utilizing the Bayes' formula.\n",
    "\n",
    "_Hint:_ Observe that the denominator in the quotient of Bayes' formula is identical for class 0 and class 1. You need not implement it if you only want to compare different class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sample(feats, mu_gb, sig_gb, mu_lic, sig_lic):\n",
    "    pdf_gb = scipy.stats.multivariate_normal(mu_gb, sig_gb).pdf    \n",
    "    pdf_lic = scipy.stats.multivariate_normal(mu_lic, sig_lic).pdf    \n",
    "    p_feat_given_gb = pdf_gb(feats)\n",
    "    p_feat_given_lic = pdf_lic(feats)\n",
    "    ### TODO: \n",
    "    # - Define the variables `p_gb` and `p_lic` (the probability of drawing a gummy \n",
    "    #   bear/piece of licorice out of the underlying set) \n",
    "    # - Define a rule deciding which class number is more likely using Bayes' formula.\n",
    "    p_gb  = ...\n",
    "    p_lic = ...\n",
    "    class_no = ...\n",
    "    ##\n",
    "    return class_no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bf284",
   "metadata": {},
   "source": [
    "### 5. Inference\n",
    "\n",
    "_**Inference**_ is the process of application of the model to unknown data. We define a function `inference` which gets the acquired grayscale image `img_gray` and the color image `img`. It repeats the same preprocessing steps we did with the training data, finds all segments and classifies them. Finally, it draws a rectangle around every segment in the color of the inferred class and returns the modified image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(img_gray, img):\n",
    "    img_preproc = preprocess(img_gray)\n",
    "    contours, contour_img = P5_helpers.compute_contours(img_preproc)\n",
    "    feats = get_features(contours)\n",
    "    print(\"Number of segments found: \", len(contours))\n",
    "    for contour, feat in zip(contours, feats):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        start_point = (x, y)\n",
    "        end_point = (x+w, y+h)\n",
    "        class_no = classify_sample(feat, mu_gb, sig_gb, mu_lic, sig_lic)\n",
    "        col = (255,0,0) if class_no == 0 else (0,255,0)\n",
    "        img = cv2.rectangle(img, start_point, end_point, col, 10)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ea50b",
   "metadata": {},
   "source": [
    "Let's try it with the image `samples.jpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c50dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, orig_img = acquire(\"samples.jpg\")\n",
    "result = inference(img, orig_img)\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "P5_helpers.disp_img(ax, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12f224",
   "metadata": {},
   "source": [
    "### Further things to do if you dare:\n",
    "\n",
    "We have also provided for you further test samples `samples2.jpg` and `samples3.jpg`. They differ significantly from `samples.jpg` and the training data. Identify the difference and try to make your classifier work even with these samples. (This is difficult!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a3ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
